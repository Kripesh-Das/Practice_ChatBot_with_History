{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f36a6335ad0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f36a63df050>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Kripesh Das, and you're aspiring to become a Gen-AI and CUDA Engineer! \\n\\nIt's great to have those aspirations. Gen-AI and CUDA are both cutting-edge fields with lots of potential for innovation.  \\n\\nIs there anything specific you'd like to know or discuss about those goals right now?  I'm happy to help in any way I can.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 274, 'total_tokens': 361, 'completion_time': 0.158181818, 'prompt_time': 0.022344628, 'queue_time': 0.0028503500000000015, 'total_time': 0.180526446}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5c43700b-b291-4a3a-8965-684bbee5b92d-0', usage_metadata={'input_tokens': 274, 'output_tokens': 87, 'total_tokens': 361})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi I am Kripesh Das and I am an aspiring Gen-AI and CUDA Engineering\"),\n",
    "        AIMessage(content=\"Hi Kripesh Das,\\n\\nIt's great to meet you!  It sounds like you have some exciting goals in the world of AI and computing.  \\n\\n**Gen-AI, AI, and CUDA Engineering** are all incredibly hot fields right now. \\n\\n**To help me understand your aspirations better, could you tell me a bit more about:**\\n\\n* **What specifically interests you about Gen-AI?**  Are you drawn to the creative potential, the ability to generate realistic text and code, or something else entirely?\\n* **What kind of AI engineering are you most interested in?**  Do you see yourself working on machine learning algorithms, building AI applications, or something else?\\n* **How does CUDA fit into your plans?** Are you interested in optimizing AI models for GPUs, or are you looking to explore other aspects of CUDA programming?\\n\\nThe more you tell me about your interests, the better I can help you explore resources, connect with people in the field, and brainstorm potential career paths. \\n\\nI'm excited to learn more about your journey!\\n\"),\n",
    "        HumanMessage(content=\"Hey what's my name again ,along with my aspiring goals?\")\n",
    "    ]\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MESSAGE HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "         [HumanMessage(content=\"Hi I am Kripesh Das and I am an aspiring Gen-AI and CUDA Engineering\")],\n",
    "         config=config\n",
    "        )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Kripesh, it's great to meet you! \\n\\nIt sounds like you're passionate about cutting-edge technology.  Gen-AI, AI, and CUDA are all incredibly exciting fields with immense potential. \\n\\nTo help me understand your journey better, could you tell me a bit more about:\\n\\n* **What specifically interests you about Gen-AI, AI, and CUDA Engineering?** \\n* **What experience do you have in these areas?** (e.g., coursework, projects, etc.)\\n* **What are your goals as an aspiring engineer in these fields?**\\n\\nI'd love to hear more about your aspirations and maybe even offer some advice or resources based on your interests.  \\n\\nLet's explore the world of AI together!\\n\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Kripesh Das.  \\n\\nYou told me at the beginning of our conversation! üòä   \\n\\nIs there anything else I can help you with?\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### change the config by changing the session_id\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response = with_message_history.invoke(\n",
    "        [HumanMessage(content=\"What's my name\")],\n",
    "        config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no memory of past conversations and do not know your name.  If you'd like to tell me, I'm happy to know! üòä\\n\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### change the config by changing the session_id\n",
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_history.invoke(\n",
    "        [HumanMessage(content=\"What's my name\")],\n",
    "        config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PROMPT TEMPLATES \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Help with all the queries given to you in a precise manner\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\") \n",
    "    ]   \n",
    ")\n",
    "\n",
    "chain = prompt|model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Kripesh Das,  \\n\\nYes, your name is Kripesh Das.  \\n\\nIs there anything else I can help you with? \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 35, 'total_tokens': 70, 'completion_time': 0.063636364, 'prompt_time': 0.003062355, 'queue_time': 0.23257301200000002, 'total_time': 0.066698719}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0861a3e7-bedd-4f48-a28e-0ae90c354c2b-0', usage_metadata={'input_tokens': 35, 'output_tokens': 35, 'total_tokens': 70})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Kripesh Das\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, your name is Kripesh Das.  \\n\\nIs there anything else I can help you with? üòä \\n'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Kripesh Das\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding more complexity \n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all the queries in the best of your abilities in a precised manner in {language}\", \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Kripesh Das! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  \\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Kripesh Das\")],\n",
    "                         \"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping this into a message history class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Kripesh Das!  \\n\\n‡§Ü‡§™ ‡§ï‡•à‡§∏‡•á ‡§π‡•à‡§Ç? ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? \\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Hi,I am Kripesh Das\")],\"language\":\"Hindi\"},\n",
    "    config = config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name?\")],\"language\":\"Hindi\"},\n",
    "    config = config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Kripesh Das ‡§π‡•à‡•§ üòä \\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage the Conversational History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi I am Kripesh Das', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=' I Love manga and anime', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"That's great!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Who is the the best character from Hunter X Hunter?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I think it's KuraPika\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    "    \n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a good assistant\"),\n",
    "    HumanMessage(content=\"Hi I am Kripesh Das\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\" I Love manga and anime\"),\n",
    "    AIMessage(content=\"That's great!\"),\n",
    "    HumanMessage(content=\"Who is the the best character from Hunter X Hunter?\"),\n",
    "    AIMessage(content=\"I think it's KuraPika\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Who is the the best character from Hunter X Hunter?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I think it's KuraPika\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_core.messages import SystemMessage,trim_messages\n",
    "# trimmer = trim_messages(\n",
    "#     max_tokens = 35,\n",
    "#     strategy = \"last\",\n",
    "#     token_counter = model,\n",
    "#     include_system = True,\n",
    "#     allow_partial = False,\n",
    "#     start_on = \"human\"a\n",
    "    \n",
    "# )\n",
    "\n",
    "# messages = [\n",
    "#     SystemMessage(content=\"You are a good assistant\"),\n",
    "#     HumanMessage(content=\"Hi I am Kripesh Das\"),\n",
    "#     AIMessage(content=\"Hi!\"),\n",
    "#     HumanMessage(content=\" I Love manga and anime\"),\n",
    "#     AIMessage(content=\"That's great!\"),\n",
    "#     HumanMessage(content=\"Who is the the best character from Hunter X Hunter?\"),\n",
    "#     AIMessage(content=\"I think it's KuraPika\"),\n",
    "# ]\n",
    "\n",
    "# trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That\\'s a tough one!  \"Best\" is subjective. \\n\\nSome popular choices include:\\n\\n* **Gon Freecss:** The main protagonist, driven and optimistic.\\n* **Killua Zoldyck:** Gon\\'s best friend, a complex assassin with a kind heart.\\n* **Hisoka Morow:** A flamboyant and dangerous magician, always playing mind games.\\n* **Kurapika:**  Driven by revenge, his Nen abilities are fascinating.\\n\\nWho do *you* think is the best and why?\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"Who is the the best character from Hunter X Hunter?\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets wrap it\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key = \"messages\",\n",
    "    )\n",
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Kripesh Das.  You told me at the beginning!\\n'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"What is my name?\")],\n",
    "        \"language\": \"English\",\n",
    "    },\n",
    "    config = config,\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
